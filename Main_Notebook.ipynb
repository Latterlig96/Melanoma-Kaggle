{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from Folds_creator.Creator import Fold_Creator\n",
    "from model.models import ModelCreation\n",
    "from TFData.Dataset import Dataset\n",
    "from callbacks.CyclicLR import CyclicLR\n",
    "from utils import build_lrfn\n",
    "from tensorflow.keras.optimizers import Adam \n",
    "from tensorflow.keras.callbacks import ModelCheckpoint,LearningRateScheduler\n",
    "from tensorflow.keras.metrics import AUC,BinaryAccuracy \n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_DF = './Dataset/train.csv'\n",
    "TEST_DF = './Dataset/test.csv'\n",
    "TEST_TFRECORDS = tf.io.gfile.glob('./Dataset/tfrecords/test*.tfrec')\n",
    "TRAINING_DATA_SIZE = 33126\n",
    "TEST_DATA_SIZE = 10982\n",
    "BATCH_SIZE = 8\n",
    "IMAGE_SIZE = [1024,1024]\n",
    "RESIZE_SHAPE = [256,256]\n",
    "EPOCHS = 5 \n",
    "SHUFFLE = 256\n",
    "VALIDATION_SPLIT = 0.2\n",
    "N_SPLITS = 5\n",
    "LEARNING_RATE = 1e-5\n",
    "LR_MAX = 0.0004 \n",
    "LR_MIN = 1e-6 \n",
    "LR_RAMPUP_EPOCHS = 5\n",
    "LR_SUSTAIN_EPOCHS = 0\n",
    "LR_EXP_DECAY = 0.8\n",
    "SEED = 48\n",
    "scheduler = build_lrfn(lr_start=LEARNING_RATE,\n",
    "                        lr_max=LR_MAX,\n",
    "                        lr_min=LR_MIN,\n",
    "                        lr_rampup_epochs=LR_RAMPUP_EPOCHS,\n",
    "                        lr_sustain_epochs=0,\n",
    "                        lr_exp_decay=LR_EXP_DECAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Fold = Fold_Creator(train_df_path=TRAIN_DF,\n",
    "                        test_df_path=TEST_DF,\n",
    "                        tfrecord_path=None,\n",
    "                        fold_type='StratifiedGroupKFold',\n",
    "                        n_splits=N_SPLITS,shuffle=True,\n",
    "                        random_state=SEED,group_col='patient_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "==================== Fold_1 ====================\nSave model in path: ./model/saved_models/EfficientNetB5_fold_1.h5\nModel: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 256, 256, 3)]     0         \n_________________________________________________________________\nefficientnet-b5 (Model)      (None, 8, 8, 2048)        28513520  \n_________________________________________________________________\nglobal_average_pooling2d (Gl (None, 2048)              0         \n_________________________________________________________________\ndense (Dense)                (None, 2048)              4196352   \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 2049      \n=================================================================\nTotal params: 32,711,921\nTrainable params: 32,539,185\nNon-trainable params: 172,736\n_________________________________________________________________\nCreated model: efficientnet\nInput Shape: (256, 256, 3)\nOutput Shape: 1\nMixed precission is set\n\nEpoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\n\nEpoch 00001: LearningRateScheduler reducing learning rate to 1e-05.\nEpoch 1/5\n100/100 [==============================] - ETA: 0s - loss: 0.3816 - binary_accuracy: 0.8562 - auc: 0.3969\nEpoch 00001: val_auc improved from inf to 0.64899, saving model to ./model/saved_models/EfficientNetB5_fold_1.h5\n\nEpoch 00001: val_auc did not improve from 0.64899\n100/100 [==============================] - 164s 2s/step - loss: 0.3816 - binary_accuracy: 0.8562 - auc: 0.3969 - val_loss: 0.2650 - val_binary_accuracy: 0.9550 - val_auc: 0.6490 - lr: 1.0000e-05\n\nEpoch 00002: LearningRateScheduler reducing learning rate to 8.8e-05.\n\nEpoch 00002: LearningRateScheduler reducing learning rate to 8.8e-05.\nEpoch 2/5\n100/100 [==============================] - ETA: 0s - loss: 0.1131 - binary_accuracy: 0.9700 - auc: 0.6445\nEpoch 00002: val_auc did not improve from 0.64899\n\nEpoch 00002: val_auc did not improve from 0.64899\n100/100 [==============================] - 156s 2s/step - loss: 0.1131 - binary_accuracy: 0.9700 - auc: 0.6445 - val_loss: 0.0602 - val_binary_accuracy: 0.9900 - val_auc: 0.7159 - lr: 8.8000e-05\n\nEpoch 00003: LearningRateScheduler reducing learning rate to 0.000166.\n\nEpoch 00003: LearningRateScheduler reducing learning rate to 0.000166.\nEpoch 3/5\n100/100 [==============================] - ETA: 0s - loss: 0.0970 - binary_accuracy: 0.9750 - auc: 0.7639\nEpoch 00003: val_auc did not improve from 0.64899\n\nEpoch 00003: val_auc did not improve from 0.64899\n100/100 [==============================] - 156s 2s/step - loss: 0.0970 - binary_accuracy: 0.9750 - auc: 0.7639 - val_loss: 0.0519 - val_binary_accuracy: 0.9900 - val_auc: 0.9116 - lr: 1.6600e-04\n\nEpoch 00004: LearningRateScheduler reducing learning rate to 0.000244.\n\nEpoch 00004: LearningRateScheduler reducing learning rate to 0.000244.\nEpoch 4/5\n100/100 [==============================] - ETA: 0s - loss: 0.1299 - binary_accuracy: 0.9663 - auc: 0.7378\nEpoch 00004: val_auc did not improve from 0.64899\n\nEpoch 00004: val_auc did not improve from 0.64899\n100/100 [==============================] - 157s 2s/step - loss: 0.1299 - binary_accuracy: 0.9663 - auc: 0.7378 - val_loss: 0.0559 - val_binary_accuracy: 0.9900 - val_auc: 0.6907 - lr: 2.4400e-04\n\nEpoch 00005: LearningRateScheduler reducing learning rate to 0.000322.\n\nEpoch 00005: LearningRateScheduler reducing learning rate to 0.000322.\nEpoch 5/5\n100/100 [==============================] - ETA: 0s - loss: 0.1111 - binary_accuracy: 0.9800 - auc: 0.6721\nEpoch 00005: val_auc did not improve from 0.64899\n\nEpoch 00005: val_auc did not improve from 0.64899\n100/100 [==============================] - 156s 2s/step - loss: 0.1111 - binary_accuracy: 0.9800 - auc: 0.6721 - val_loss: 0.0510 - val_binary_accuracy: 0.9850 - val_auc: 0.7109 - lr: 3.2200e-04\nLoading model from path: ./model/saved_models/EfficientNetB5_fold_1.h5\n"
    },
    {
     "output_type": "error",
     "ename": "ValueError",
     "evalue": "zero-dimensional arrays cannot be concatenated",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-da13cdb45f18>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[0mtest_ids_images\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_ids\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTEST_DATA_SIZE\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'U'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m     \u001b[0mtest_idnums\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_ids_images\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m     \u001b[0mi\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: zero-dimensional arrays cannot be concatenated"
     ]
    }
   ],
   "source": [
    "oof_val_predictions = np.zeros((TRAINING_DATA_SIZE,))\n",
    "test_preds = np.zeros((TEST_DATA_SIZE,N_SPLITS))\n",
    "    \n",
    "i = 1\n",
    "    \n",
    "for trn_idx,val_idx,train_path,train_label,valid_path,valid_label in Fold.create_folds_generator():\n",
    "    print(\"=\"* 20,f'Fold_{i}',\"=\" * 20)\n",
    "\n",
    "    train = [train_path,train_label]\n",
    "    validation = [valid_path,valid_label]\n",
    "\n",
    "    save_path = f'./model/saved_models/EfficientNetB5_fold_{i}.h5'\n",
    "\n",
    "    print(f\"Save model in path: {save_path}\")\n",
    "\n",
    "    callbacks = [ \n",
    "        ModelCheckpoint(save_path,monitor='val_auc',verbose=1,save_best_only=True),\n",
    "        LearningRateScheduler(scheduler,verbose=1)\n",
    "    ]\n",
    "\n",
    "    Data = Dataset(\n",
    "        train_files = train,\n",
    "        test_files = TEST_TFRECORDS,\n",
    "        validation_files = validation,\n",
    "        validation_split = 0.2,\n",
    "        image_size = IMAGE_SIZE,\n",
    "        shuffle = SHUFFLE,\n",
    "        dataset_size = TRAINING_DATA_SIZE,\n",
    "        batch_size = BATCH_SIZE,\n",
    "        resize_shape = RESIZE_SHAPE\n",
    "    )\n",
    "\n",
    "    Model = ModelCreation(\n",
    "        architecture = 'efficientnet',\n",
    "        learning_rate = LEARNING_RATE,\n",
    "        input_shape = (*RESIZE_SHAPE,3),\n",
    "        output_shape = 1, \n",
    "        optimizer = Adam,\n",
    "        metric = [BinaryAccuracy(),AUC()],\n",
    "        loss = BinaryCrossentropy(),\n",
    "        linear = True,\n",
    "        verbose = True\n",
    "    )\n",
    "\n",
    "    training = Data.get_train_from_tensor_slices()\n",
    "    validation_data = Data.get_val_from_tensor_slices()\n",
    "\n",
    "    history = Model.model.fit(training,\n",
    "                                steps_per_epoch = Data.get_train_steps_per_epoch(),\n",
    "                                epochs = EPOCHS,\n",
    "                                validation_data = validation_data,\n",
    "                                validation_steps = Data.get_validation_steps_per_epoch(),\n",
    "                                verbose = 1,\n",
    "                                callbacks = Model.inject_callbacks(callbacks))\n",
    "\n",
    "    print(f\"Loading model from path: {save_path}\")\n",
    "\n",
    "    Load_model = load_model(save_path)\n",
    "\n",
    "    validation_images = validation_data.map(lambda image,label: image)\n",
    "    \n",
    "    probabilities = Load_model.predict(validation_images)\n",
    "\n",
    "    oof_val_predictions[val_idx] = np.concatenate(probabilities)\n",
    "\n",
    "    #Get test set predictions in fold \n",
    "\n",
    "    test_data = Data.get_test_dataset()\n",
    "\n",
    "    test_images = test_data.map(lambda image,idnum : image)\n",
    "    test_probabilities = Load_model.predict(test_images)\n",
    "\n",
    "    test_preds[:,i] = np.concatenate(test_probabilities)\n",
    "\n",
    "    i += 1 \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}