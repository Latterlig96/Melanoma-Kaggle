{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "from TFData.Dataset import Dataset\n",
    "from model.models import ModelCreation\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [1024,1024]\n",
    "IMAGE_SIZE_DESIRED = [256,256]\n",
    "DATASET_SIZE = 33127\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_dataset = tf.io.gfile.glob('./Dataset/tfrecords/train*.tfrec')\n",
    "test_dataset = tf.io.gfile.glob('./Dataset/tfrecords/test*.tfrec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DataGenerator = Dataset(train_files=training_dataset,\n",
    "                        test_files=test_dataset,\n",
    "                        validation_split=0.2,\n",
    "                        image_size=IMAGE_SIZE,\n",
    "                        dataset_size=DATASET_SIZE,\n",
    "                        batch_size=BATCH_SIZE,\n",
    "                        resize_shape=IMAGE_SIZE_DESIRED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here if you want to create training and validation dataset you must invoke get_train_and_validation_dataset\n",
    "# ... at least I hope so \n",
    "DataGenerator.get_train_and_validation_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"model\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ninput_1 (InputLayer)         [(None, 256, 256, 3)]     0         \n_________________________________________________________________\nefficientnet-b5 (Model)      (None, 8, 8, 2048)        28513520  \n_________________________________________________________________\nglobal_average_pooling2d (Gl (None, 2048)              0         \n_________________________________________________________________\ndense (Dense)                (None, 2048)              4196352   \n_________________________________________________________________\ndense_1 (Dense)              (None, 1)                 2049      \n=================================================================\nTotal params: 32,711,921\nTrainable params: 32,539,185\nNon-trainable params: 172,736\n_________________________________________________________________\nCreated model: efficientnet\nInput Shape: (256, 256, 3)\nOutput Shape: 1\nMixed precission is set\n"
    }
   ],
   "source": [
    "model_util = ModelCreation(architecture='efficientnet',\n",
    "                      learning_rate= 0.00075,\n",
    "                      input_shape=(*IMAGE_SIZE_DESIRED,3),\n",
    "                      output_shape=1,\n",
    "                      linear=True,\n",
    "                      verbose=True,\n",
    "                      loss = binary_crossentropy,\n",
    "                      optimizer = Adam,\n",
    "                      metric = binary_crossentropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    ModelCheckpoint('my_model.h5',monitor='val_loss',verbose=1,save_best_only=True),\n",
    "    EarlyStopping(patience=2)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "WARNING: Logging before flag parsing goes to stderr.\nW0608 17:20:13.690399 16032 deprecation.py:323] From <ipython-input-16-5e53364b4b2e>:8: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\nInstructions for updating:\nPlease use Model.fit, which supports generators.\nEpoch 1/5\n3313/3313 [==============================] - ETA: 0s - loss: 0.1015 - binary_crossentropy: 0.1018\nEpoch 00001: val_loss improved from inf to 0.07945, saving model to my_model.h5\n\nEpoch 00001: val_loss did not improve from 0.07945\n3313/3313 [==============================] - 4939s 1s/step - loss: 0.1015 - binary_crossentropy: 0.1018 - val_loss: 0.0795 - val_binary_crossentropy: 0.0795\nEpoch 2/5\n3313/3313 [==============================] - ETA: 0s - loss: 0.0890 - binary_crossentropy: 0.0890\nEpoch 00002: val_loss improved from 0.07945 to 0.07785, saving model to my_model.h5\n\nEpoch 00002: val_loss did not improve from 0.07785\n3313/3313 [==============================] - 4932s 1s/step - loss: 0.0890 - binary_crossentropy: 0.0890 - val_loss: 0.0778 - val_binary_crossentropy: 0.0778\nEpoch 3/5\n3313/3313 [==============================] - ETA: 0s - loss: 0.0869 - binary_crossentropy: 0.0870\nEpoch 00003: val_loss did not improve from 0.07785\n\nEpoch 00003: val_loss did not improve from 0.07785\n3313/3313 [==============================] - 4928s 1s/step - loss: 0.0869 - binary_crossentropy: 0.0870 - val_loss: 0.0804 - val_binary_crossentropy: 0.0804\n"
    }
   ],
   "source": [
    "history = model_util.model.fit_generator(\n",
    "                                DataGenerator.train_tfdataset,\n",
    "                                steps_per_epoch = DataGenerator.get_train_steps_per_epoch(),\n",
    "                                epochs = 5,\n",
    "                                validation_data = DataGenerator.validation_tfdataset,\n",
    "                                validation_steps = DataGenerator.get_validation_steps_per_epoch(),\n",
    "                                verbose = 1,\n",
    "                                callbacks=model_util.inject_callbacks(callbacks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = DataGenerator.get_test_dataset()\n",
    "test_images = test_dataset.map(lambda image,idnum:tf.image.resize(image,[256,256]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "Loaded_model = load_model('my_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "probabilites = Loaded_model.predict(test_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_TEST_IMAGES = 10982\n",
    "test_ids_ds = test_dataset.map(lambda image,idnum: idnum).unbatch()\n",
    "test_ids = next(iter(test_ids_ds.batch(NUM_TEST_IMAGES))).numpy().astype('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('./Dataset/sample_submission.csv')\n",
    "pred_df = pd.DataFrame({'image_name': test_ids,'target': np.concatenate(probabilites)})\n",
    "del sub['target']\n",
    "sub = sub.merge(pred_df,on='image_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"EfficientNetB5Sub.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}